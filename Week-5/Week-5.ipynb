{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Week 5\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "- [Capstone Objectives](#Capstone-Objectives)\n",
    "- [Read in Data](#Read-in-Data)\n",
    "    - [Merge 2018 and 2019](#Merge-2018-and-2019)\n",
    "    - [Make advisor dictionary mapper](#Make-advisor-dictionary-mapper)\n",
    "- [Pandas Profiling](#Pandas-Profiling)\n",
    "- [Missing Data](#Missing-Data)\n",
    "    - [How big of a problem is missing data?](#How-big-of-a-problem-is-missing-data?)\n",
    "    - [Three types of missing data](#Three-types-of-missing-data)\n",
    "    - [Strategies for handling missing data](#Strategies-for-handling-missing-data)\n",
    "        - [Weight Class Adjustment Example](#Weight-Class-Adjustment-Example)\n",
    "    - [Imputation Strategies](#Imputation-Strategies)\n",
    "    - [Missingness Tests](#Missingness-Tests)\n",
    "    - [MCAR Data](#MCAR-Data)\n",
    "    - [MAR Data](#MAR-Data)\n",
    "    - [NMAR Data](#NMAR-Data)\n",
    "    - [Missing data workflow](#Missing-data-workflow)\n",
    "- [Data Cleaning](#Data-Cleaning)\n",
    "    - [Train-Test-Split](#Train-Test-Split)\n",
    "    - [Custom Cleaning Functions](#Custom-Cleaning-Functions)\n",
    "    - [Create Cleaning Pipeline](#Create-Cleaning-Pipeline)\n",
    "- [Model building](#Model-building)\n",
    "- [Make predictions](#Make-predictions)\n",
    "- [Feature Engineering](#Feature-Engineering)\n",
    "    - [Variable Inflation Factor (VIF)](#Variable-Inflation-Factor-(VIF))\n",
    "- [Residuals](#Residuals)\n",
    "- [Classification](#Classification)\n",
    "- [Model Interpretation](#Model-Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Objectives\n",
    "- Assist sales and marketing by improving their targeting\n",
    "- Predict sales for 2019 using the data for 2018\n",
    "- Estimate the probability of adding a new fund in 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df18 = pd.read_excel(\"../Transaction Data.xlsx\", sheet_name=\"Transactions18\")\n",
    "df19 = pd.read_excel(\"../Transaction Data.xlsx\", sheet_name=\"Transactions19\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge 2018 and 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10005, 41)\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(\n",
    "    df18, \n",
    "    df19, \n",
    "    on='CONTACT_ID',\n",
    "    suffixes=['_2018', '_2019']\n",
    ")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTACT_ID</th>\n",
       "      <th>no_of_sales_12M_1</th>\n",
       "      <th>no_of_Redemption_12M_1</th>\n",
       "      <th>no_of_sales_12M_10K</th>\n",
       "      <th>no_of_Redemption_12M_10K</th>\n",
       "      <th>no_of_funds_sold_12M_1</th>\n",
       "      <th>no_of_funds_redeemed_12M_1</th>\n",
       "      <th>no_of_fund_sales_12M_10K</th>\n",
       "      <th>no_of_funds_Redemption_12M_10K</th>\n",
       "      <th>no_of_assetclass_sold_12M_1</th>\n",
       "      <th>no_of_assetclass_redeemed_12M_1</th>\n",
       "      <th>no_of_assetclass_sales_12M_10K</th>\n",
       "      <th>no_of_assetclass_Redemption_12M_10K</th>\n",
       "      <th>No_of_fund_curr</th>\n",
       "      <th>No_of_asset_curr</th>\n",
       "      <th>AUM</th>\n",
       "      <th>sales_curr</th>\n",
       "      <th>sales_12M_2018</th>\n",
       "      <th>redemption_curr</th>\n",
       "      <th>redemption_12M</th>\n",
       "      <th>new_Fund_added_12M_2018</th>\n",
       "      <th>aum_AC_EQUITY</th>\n",
       "      <th>aum_AC_FIXED_INCOME_MUNI</th>\n",
       "      <th>aum_AC_FIXED_INCOME_TAXABLE</th>\n",
       "      <th>aum_AC_MONEY</th>\n",
       "      <th>aum_AC_MULTIPLE</th>\n",
       "      <th>aum_AC_PHYSICAL_COMMODITY</th>\n",
       "      <th>aum_AC_REAL_ESTATE</th>\n",
       "      <th>aum_AC_TARGET</th>\n",
       "      <th>aum_P_529</th>\n",
       "      <th>aum_P_ALT</th>\n",
       "      <th>aum_P_CEF</th>\n",
       "      <th>aum_P_ETF</th>\n",
       "      <th>aum_P_MF</th>\n",
       "      <th>aum_P_SMA</th>\n",
       "      <th>aum_P_UCITS</th>\n",
       "      <th>aum_P_UIT</th>\n",
       "      <th>refresh_date_2018</th>\n",
       "      <th>sales_12M_2019</th>\n",
       "      <th>new_Fund_added_12M_2019</th>\n",
       "      <th>refresh_date_2019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0047433</td>\n",
       "      <td>21.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>237480.11</td>\n",
       "      <td>250.0</td>\n",
       "      <td>19682.0</td>\n",
       "      <td>-1496.745</td>\n",
       "      <td>-102496.165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-47342.32</td>\n",
       "      <td>284737.93</td>\n",
       "      <td>84.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>122866.04</td>\n",
       "      <td>114614.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>18633.105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4461312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19629.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19629.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19629.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4491079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1758.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1758.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1758.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0107408</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57943.00</td>\n",
       "      <td>5459.0</td>\n",
       "      <td>52484.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57943.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57943.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>93212.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>85101140503769936458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8573.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8573.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8573.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CONTACT_ID  no_of_sales_12M_1  no_of_Redemption_12M_1  \\\n",
       "0               0047433               21.0                    38.0   \n",
       "1               4461312                NaN                     NaN   \n",
       "2               4491079                NaN                     NaN   \n",
       "3               0107408               20.0                     NaN   \n",
       "4  85101140503769936458                NaN                     NaN   \n",
       "\n",
       "   no_of_sales_12M_10K  no_of_Redemption_12M_10K  no_of_funds_sold_12M_1  \\\n",
       "0                  NaN                       1.0                     5.0   \n",
       "1                  NaN                       NaN                     NaN   \n",
       "2                  NaN                       NaN                     NaN   \n",
       "3                  2.0                       NaN                     1.0   \n",
       "4                  NaN                       NaN                     NaN   \n",
       "\n",
       "   no_of_funds_redeemed_12M_1  no_of_fund_sales_12M_10K  \\\n",
       "0                         5.0                       NaN   \n",
       "1                         NaN                       NaN   \n",
       "2                         NaN                       NaN   \n",
       "3                         NaN                       1.0   \n",
       "4                         NaN                       NaN   \n",
       "\n",
       "   no_of_funds_Redemption_12M_10K  no_of_assetclass_sold_12M_1  \\\n",
       "0                             1.0                          2.0   \n",
       "1                             NaN                          NaN   \n",
       "2                             NaN                          NaN   \n",
       "3                             NaN                          1.0   \n",
       "4                             NaN                          NaN   \n",
       "\n",
       "   no_of_assetclass_redeemed_12M_1  no_of_assetclass_sales_12M_10K  \\\n",
       "0                              2.0                             NaN   \n",
       "1                              NaN                             NaN   \n",
       "2                              NaN                             NaN   \n",
       "3                              NaN                             1.0   \n",
       "4                              NaN                             NaN   \n",
       "\n",
       "   no_of_assetclass_Redemption_12M_10K  No_of_fund_curr  No_of_asset_curr  \\\n",
       "0                                  1.0              8.0               1.0   \n",
       "1                                  NaN              1.0               1.0   \n",
       "2                                  NaN              NaN               NaN   \n",
       "3                                  NaN              1.0               1.0   \n",
       "4                                  NaN              NaN               NaN   \n",
       "\n",
       "         AUM  sales_curr  sales_12M_2018  redemption_curr  redemption_12M  \\\n",
       "0  237480.11       250.0         19682.0        -1496.745     -102496.165   \n",
       "1   19629.00         NaN             NaN              NaN             NaN   \n",
       "2    1758.70         NaN             NaN              NaN             NaN   \n",
       "3   57943.00      5459.0         52484.0              NaN             NaN   \n",
       "4   -8573.59         NaN             NaN              NaN             NaN   \n",
       "\n",
       "   new_Fund_added_12M_2018  aum_AC_EQUITY  aum_AC_FIXED_INCOME_MUNI  \\\n",
       "0                      NaN      -47342.32                 284737.93   \n",
       "1                      NaN           0.00                  19629.00   \n",
       "2                      NaN           0.00                   1758.70   \n",
       "3                      1.0           0.00                      0.00   \n",
       "4                      NaN       -8573.59                      0.00   \n",
       "\n",
       "   aum_AC_FIXED_INCOME_TAXABLE  aum_AC_MONEY  aum_AC_MULTIPLE  \\\n",
       "0                         84.5           0.0              0.0   \n",
       "1                          0.0           0.0              0.0   \n",
       "2                          0.0           0.0              0.0   \n",
       "3                      57943.0           0.0              0.0   \n",
       "4                          0.0           0.0              0.0   \n",
       "\n",
       "   aum_AC_PHYSICAL_COMMODITY  aum_AC_REAL_ESTATE  aum_AC_TARGET  aum_P_529  \\\n",
       "0                        0.0                 0.0            0.0        0.0   \n",
       "1                        0.0                 0.0            0.0        0.0   \n",
       "2                        0.0                 0.0            0.0        0.0   \n",
       "3                        0.0                 0.0            0.0        0.0   \n",
       "4                        0.0                 0.0            0.0        0.0   \n",
       "\n",
       "   aum_P_ALT  aum_P_CEF  aum_P_ETF   aum_P_MF  aum_P_SMA  aum_P_UCITS  \\\n",
       "0        0.0        0.0        0.0  122866.04  114614.07          0.0   \n",
       "1        0.0        0.0        0.0   19629.00       0.00          0.0   \n",
       "2        0.0        0.0        0.0    1758.70       0.00          0.0   \n",
       "3        0.0        0.0        0.0   57943.00       0.00          0.0   \n",
       "4        0.0        0.0        0.0   -8573.59       0.00          0.0   \n",
       "\n",
       "   aum_P_UIT refresh_date_2018  sales_12M_2019  new_Fund_added_12M_2019  \\\n",
       "0        0.0        2018-12-31       18633.105                      NaN   \n",
       "1        0.0        2018-12-31             NaN                      NaN   \n",
       "2        0.0        2018-12-31             NaN                      NaN   \n",
       "3        0.0        2018-12-31       93212.000                      1.0   \n",
       "4        0.0        2018-12-31             NaN                      NaN   \n",
       "\n",
       "  refresh_date_2019  \n",
       "0        2019-12-31  \n",
       "1        2019-12-31  \n",
       "2        2019-12-31  \n",
       "3        2019-12-31  \n",
       "4        2019-12-31  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make advisor dictionary mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adviser_lookup = {idx: contact_id for idx, contact_id in enumerate(df['CONTACT_ID'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'85201142414218755394'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adviser_lookup[123]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Pandas Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -yc conda-forge pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_diagrams = {\n",
    "#     'heatmap': True, 'dendrogram': True, 'matrix': True, 'bar': True\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = ProfileReport(df, title='Nuveen Profile Report')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9997f9d9a2478887b2c494b67a4589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Summarize dataset', max=50.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd0604eb31248218b8a78d6bd8ec96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generate report structure', max=1.0, style=ProgressStyle(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Render widgets', max=1.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0532c879324d579659eda9a4277e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile.to_file(output_file=\"nuveen_profiling.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point we haven't put much thought into dealing with missing data. Missing data is EVERYWHERE and it's important to know how to do data science with missing data. It can significantly undermine our results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How big of a problem is missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is difficult question because we only see what we observe. We can use simulated data to help answer this question, but we cannot quantify the impact of missing data in our real data projects.\n",
    "\n",
    "See this resource: https://github.com/matthewbrems/jupytercon-missing-data-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three types of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **MCAR**: Missing Completely at Random\n",
    "    - Some intern spills their coffee on your surveys in random order\n",
    "    - Flip coin of missingness\n",
    "    \n",
    "    \n",
    "2. **MAR**: Missing at Random\n",
    "    - I adminster a survey about income. Those who aare female are less likely to respond to the question about income.\n",
    "    - Missing data is conditional on data have observed.\n",
    "\n",
    "\n",
    "3. **NMAR**: Not Missing at Random (Worst type!)\n",
    "    - I adminster a survey that includes a question about income. Those who have lower incomes are less likely to respond to the question about income.\n",
    "    - Data of interest are systematically different for respondents and nonrespondents\n",
    "    - Whether the data are missing or not depends on the value of the unobserved value itself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Strategies for handling missing data\n",
    "1. **Avoid it** (best option, if possible)\n",
    "    - Use sound design when collecting data\n",
    "    - Improve survey questioning and design\n",
    "    - Drop all rows with _any_ missing value\n",
    "    \n",
    "    \n",
    "2. **Ignore it** (second best option, if possible): \n",
    "    - Assume your respondents are close enough to the sample of non-respondents\n",
    "    - Drop any observation with _any_ missing value\n",
    "    \n",
    "    \n",
    "3. **Account for it** (most common):\n",
    "    - Weight class adjustments\n",
    "    - Determine why data are missing\n",
    "    - Employ a strategy for accounting for missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "### Weight Class Adjustment Example\n",
    "\n",
    "I'm estimating job satisfaction among two departments: finance and accounting. Both departments are the same size (A: 50%, F: 50%).\n",
    "\n",
    "$$W_{finance} = \\frac{true\\;proportion}{proportion\\;of\\;responses} = \\frac{0.50}{0.25} = 2$$\n",
    "<br>\n",
    "$$W_{accounting} = \\frac{true\\;proportion}{proportion\\;of\\;responses} = \\frac{0.50}{0.75} = \\frac{2}{3}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Imputation Strategies\n",
    "\n",
    "1. Deductive Imputation: use logical relationships to fill in value **VALID**\n",
    "\n",
    "    - Respondent says the were not victim of crime, but left \"victim of a violent crime\" question blank.\n",
    "    - If someone has 2 children in year 1, `NaN` children in year 2, and 2 children in year 3, we can _probably_ impute that in year 2 they still had 2 children.\n",
    "    - PRO: Valid method, requires minimal \"inference\"\n",
    "    - CON: Time consuming and requires specific coding\n",
    "\n",
    "\n",
    "2. Mean/Median/Mode: use measure central tendency to fill value **INVALID**\n",
    "\n",
    "     - PRO: Easy to implement\n",
    "     - CON: Significantly distorts histogram (underestimates variance) and results will look more precise than they really are\n",
    "     \n",
    "\n",
    "3. Regression Imputation: replace missing based on predicted value from regression line **INVALID**\n",
    "\n",
    "    - PRO: Easy to understand\n",
    "    - CON: Distorts distribution and underestimates variance still because there is no randomness in the prediction\n",
    "    \n",
    "    \n",
    "4. Stochastic Regression Imputation:\n",
    "\n",
    "    - Replace missing with predicted value from regression line plus random draw from normal distribution `N(0, s)`, where `s` is estimataed from model residuals **INVALID**\n",
    "    \n",
    "    - PRO: Easy to understand and better than just regression technique\n",
    "    - CON: Still under estimate variance because selecting single point from normal distribution of error\n",
    "    \n",
    "    \n",
    "5. Multiply Stochastic Regression Imputation: pull multiple values from distribution. Replace missing with predicted value from line with random error.\n",
    "\n",
    "    - PRO: Better than number 4\n",
    "    - CON: All `Beta` coefficients are constant, so still not credible\n",
    "    \n",
    "    \n",
    "6. Proper Multiply Stochastic Regression Imputation: Called Multiple Imputation by Chained Equations [(MICE)](https://stats.stackexchange.com/questions/421545/multiple-imputation-by-chained-equations-mice-explained)\n",
    "\n",
    "    - Create `n` copies of your data set (let's say, 10)\n",
    "    - For each dataset:\n",
    "        - Generate coefficients for your regression model\n",
    "            - For each missing value:\n",
    "                - Replace `NaN` with a value predicted from a regression\n",
    "            - Do your \"final analysis\" or generate your final prediction\n",
    "    - Aggregate your analysis/predictions across all data sets so you have one complete analysis\n",
    "    - These predictions were created by properly estimating the variance in your data\n",
    "    - PRO: Very good method, **VALID**\n",
    "    - CON: Takes more effort to implement (`fancyimpute` or `mice` in R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Missingness Tests\n",
    "\n",
    "1. Little's Test for MCAR\n",
    "    - $H_0 : MCAR$\n",
    "    - $H_A : MAR$\n",
    "    - There is no test for NMAR!\n",
    "2. Split your data into \"observed\" and \"unobserved\" and compare them\n",
    "    - Split missing `income` and observed `income` sets. Do the other variables have the same distributions?\n",
    "3. Think about missing data process. Can you come up with a reasonable answer based on how missing data came about?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## MCAR Data\n",
    "\n",
    "Use any of the methods we previously discussed:\n",
    "- Deductive imputation\n",
    "- Proper imputation\n",
    "- Stochastic Regression Imputation\n",
    "- Complete-Case Removal (unbiased, but variance will be higher because our sample size is smaller!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAR Data\n",
    "\n",
    "Use one of the following methods:\n",
    "- Deductive imputation\n",
    "- Proper imputation\n",
    "- Stochastic Regression Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NMAR Data\n",
    "\n",
    "Use one of the following methods:\n",
    "- Deductive imputation\n",
    "- Advanced methods: selection models and pattern mixture models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Missing data workflow\n",
    "1. How much missing data do I have?\n",
    "2. For each variable, estimate the type of missing data\n",
    "3. What is the best method for handling missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a variable to keep all of the columns we want to drop\n",
    "COLS_TO_DROP = [\n",
    "    'refresh_date_2019', 'refresh_date_2018', 'CONTACT_ID', \n",
    "]\n",
    "\n",
    "COLS_TO_KEEP = [\n",
    "    'no_of_sales_12M_1', 'no_of_Redemption_12M_1', 'no_of_sales_12M_10K',\n",
    "    'no_of_Redemption_12M_10K', 'no_of_funds_sold_12M_1',\n",
    "    'no_of_funds_redeemed_12M_1', 'no_of_fund_sales_12M_10K',\n",
    "    'no_of_funds_Redemption_12M_10K', 'no_of_assetclass_sold_12M_1',\n",
    "    'no_of_assetclass_redeemed_12M_1', 'no_of_assetclass_sales_12M_10K',\n",
    "    'no_of_assetclass_Redemption_12M_10K', 'No_of_fund_curr',\n",
    "    'No_of_asset_curr', 'AUM', 'sales_curr', 'sales_12M_2018',\n",
    "    'redemption_curr', 'redemption_12M', 'new_Fund_added_12M_2018',\n",
    "    'aum_AC_EQUITY', 'aum_AC_FIXED_INCOME_MUNI',\n",
    "    'aum_AC_FIXED_INCOME_TAXABLE', 'aum_AC_MONEY', 'aum_AC_MULTIPLE',\n",
    "    'aum_AC_PHYSICAL_COMMODITY', 'aum_AC_REAL_ESTATE', 'aum_AC_TARGET',\n",
    "    'aum_P_529', 'aum_P_ALT', 'aum_P_CEF', 'aum_P_ETF', 'aum_P_MF',\n",
    "    'aum_P_SMA', 'aum_P_UCITS', 'aum_P_UIT'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['sales_12M_2019', 'new_Fund_added_12M_2019'], axis=1)\n",
    "y_reg = df['sales_12M_2019']\n",
    "y_cl = df['new_Fund_added_12M_2019']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.25, random_state=24\n",
    ")\n",
    "y_train_cl, y_test_cl = y_cl[y_train_reg.index], y_cl[y_test_reg.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_columns(df):\n",
    "    '''extract out columns not listed in COLS_TO_DROP variable'''\n",
    "    cols_to_keep = [col for col in df.columns if col not in COLS_TO_DROP]\n",
    "    return df.loc[:, cols_to_keep].copy()\n",
    "\n",
    "\n",
    "def fillna_values(df):\n",
    "    '''fill nan values with zero'''\n",
    "    if isinstance(df, type(pd.Series(dtype='float64'))):\n",
    "        return df.fillna(0)\n",
    "    elif isinstance(df, type(pd.DataFrame())):\n",
    "        num_df = df.select_dtypes(include=['number']).fillna(0)\n",
    "        non_num_df = df.select_dtypes(exclude=['number'])\n",
    "        return pd.concat([num_df, non_num_df], axis=1)\n",
    "    else:\n",
    "        return np.nan_to_num(df)\n",
    "\n",
    "def negative_to_zero(series):\n",
    "    '''fill negative values to zero'''\n",
    "    if isinstance(series, type(pd.Series(dtype='float64'))):\n",
    "        return series.apply(lambda x: max(0, x))\n",
    "    else:\n",
    "        return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Create Cleaning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_columns_trans = FunctionTransformer(extract_columns)\n",
    "fillna_values_trans = FunctionTransformer(fillna_values)\n",
    "negative_to_zero_trans = FunctionTransformer(negative_to_zero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pipeline for target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "targ_pipe = Pipeline([\n",
    "    ('fillna_values_trans', fillna_values_trans),\n",
    "    ('negative_to_zero', negative_to_zero_trans)\n",
    "#     ('num_imp', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "targ_pipe.fit(y_train_reg.to_frame())\n",
    "\n",
    "y_train_reg = targ_pipe.fit_transform(y_train_reg) # fit and transform TRAINING\n",
    "y_train_cl = targ_pipe.fit_transform(y_train_cl)\n",
    "\n",
    "y_test_reg = targ_pipe.transform(y_test_reg) # transform only TESTING\n",
    "y_test_cl = targ_pipe.transform(y_test_cl) # transform only TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make pipeline for features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_pipe = Pipeline([\n",
    "    ('extract_columns_trans', extract_columns_trans),\n",
    "    ('fillna_values_trans', fillna_values_trans),\n",
    "    ('StandardScaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "train_array = feat_pipe.fit(X_train, y_train_reg).transform(X_train)\n",
    "\n",
    "X_train_prepared = pd.DataFrame(\n",
    "    train_array,\n",
    "    index=X_train.index,\n",
    "    columns=COLS_TO_KEEP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_sales_12M_1</th>\n",
       "      <th>no_of_Redemption_12M_1</th>\n",
       "      <th>no_of_sales_12M_10K</th>\n",
       "      <th>no_of_Redemption_12M_10K</th>\n",
       "      <th>no_of_funds_sold_12M_1</th>\n",
       "      <th>no_of_funds_redeemed_12M_1</th>\n",
       "      <th>no_of_fund_sales_12M_10K</th>\n",
       "      <th>no_of_funds_Redemption_12M_10K</th>\n",
       "      <th>no_of_assetclass_sold_12M_1</th>\n",
       "      <th>no_of_assetclass_redeemed_12M_1</th>\n",
       "      <th>no_of_assetclass_sales_12M_10K</th>\n",
       "      <th>no_of_assetclass_Redemption_12M_10K</th>\n",
       "      <th>No_of_fund_curr</th>\n",
       "      <th>No_of_asset_curr</th>\n",
       "      <th>AUM</th>\n",
       "      <th>sales_curr</th>\n",
       "      <th>sales_12M_2018</th>\n",
       "      <th>redemption_curr</th>\n",
       "      <th>redemption_12M</th>\n",
       "      <th>new_Fund_added_12M_2018</th>\n",
       "      <th>aum_AC_EQUITY</th>\n",
       "      <th>aum_AC_FIXED_INCOME_MUNI</th>\n",
       "      <th>aum_AC_FIXED_INCOME_TAXABLE</th>\n",
       "      <th>aum_AC_MONEY</th>\n",
       "      <th>aum_AC_MULTIPLE</th>\n",
       "      <th>aum_AC_PHYSICAL_COMMODITY</th>\n",
       "      <th>aum_AC_REAL_ESTATE</th>\n",
       "      <th>aum_AC_TARGET</th>\n",
       "      <th>aum_P_529</th>\n",
       "      <th>aum_P_ALT</th>\n",
       "      <th>aum_P_CEF</th>\n",
       "      <th>aum_P_ETF</th>\n",
       "      <th>aum_P_MF</th>\n",
       "      <th>aum_P_SMA</th>\n",
       "      <th>aum_P_UCITS</th>\n",
       "      <th>aum_P_UIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>-0.131327</td>\n",
       "      <td>-0.100418</td>\n",
       "      <td>-0.210641</td>\n",
       "      <td>-0.198657</td>\n",
       "      <td>-0.153437</td>\n",
       "      <td>-0.626787</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.441804</td>\n",
       "      <td>0.201462</td>\n",
       "      <td>-0.868033</td>\n",
       "      <td>-0.53463</td>\n",
       "      <td>-0.562039</td>\n",
       "      <td>-0.372488</td>\n",
       "      <td>0.065543</td>\n",
       "      <td>-0.088949</td>\n",
       "      <td>-0.083247</td>\n",
       "      <td>-0.154606</td>\n",
       "      <td>0.090417</td>\n",
       "      <td>0.156246</td>\n",
       "      <td>0.436844</td>\n",
       "      <td>-0.026493</td>\n",
       "      <td>-0.070601</td>\n",
       "      <td>-0.059801</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>-0.023802</td>\n",
       "      <td>-0.041821</td>\n",
       "      <td>-0.037655</td>\n",
       "      <td>-0.040002</td>\n",
       "      <td>-0.070366</td>\n",
       "      <td>-0.030628</td>\n",
       "      <td>-0.093547</td>\n",
       "      <td>-0.018485</td>\n",
       "      <td>-0.056351</td>\n",
       "      <td>-0.057933</td>\n",
       "      <td>-0.016559</td>\n",
       "      <td>-0.070033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.064598</td>\n",
       "      <td>-0.068134</td>\n",
       "      <td>-0.210641</td>\n",
       "      <td>-0.087441</td>\n",
       "      <td>1.954284</td>\n",
       "      <td>1.399401</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>1.188127</td>\n",
       "      <td>1.034363</td>\n",
       "      <td>-0.53463</td>\n",
       "      <td>0.777535</td>\n",
       "      <td>3.177868</td>\n",
       "      <td>1.018590</td>\n",
       "      <td>-0.124508</td>\n",
       "      <td>-0.082219</td>\n",
       "      <td>-0.139641</td>\n",
       "      <td>0.090417</td>\n",
       "      <td>0.071676</td>\n",
       "      <td>3.848384</td>\n",
       "      <td>0.050153</td>\n",
       "      <td>-0.166822</td>\n",
       "      <td>-0.059801</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>-0.023802</td>\n",
       "      <td>-0.041821</td>\n",
       "      <td>-0.037655</td>\n",
       "      <td>0.047651</td>\n",
       "      <td>1.121516</td>\n",
       "      <td>-0.030628</td>\n",
       "      <td>-0.093547</td>\n",
       "      <td>-0.018485</td>\n",
       "      <td>-0.160696</td>\n",
       "      <td>-0.158246</td>\n",
       "      <td>-0.016559</td>\n",
       "      <td>3.269629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      no_of_sales_12M_1  no_of_Redemption_12M_1  no_of_sales_12M_10K  \\\n",
       "4081          -0.131327               -0.100418            -0.210641   \n",
       "184            0.064598               -0.068134            -0.210641   \n",
       "\n",
       "      no_of_Redemption_12M_10K  no_of_funds_sold_12M_1  \\\n",
       "4081                 -0.198657               -0.153437   \n",
       "184                  -0.087441                1.954284   \n",
       "\n",
       "      no_of_funds_redeemed_12M_1  no_of_fund_sales_12M_10K  \\\n",
       "4081                   -0.626787                     -0.43   \n",
       "184                     1.399401                     -0.43   \n",
       "\n",
       "      no_of_funds_Redemption_12M_10K  no_of_assetclass_sold_12M_1  \\\n",
       "4081                       -0.441804                     0.201462   \n",
       "184                         0.296800                     1.188127   \n",
       "\n",
       "      no_of_assetclass_redeemed_12M_1  no_of_assetclass_sales_12M_10K  \\\n",
       "4081                        -0.868033                        -0.53463   \n",
       "184                          1.034363                        -0.53463   \n",
       "\n",
       "      no_of_assetclass_Redemption_12M_10K  No_of_fund_curr  No_of_asset_curr  \\\n",
       "4081                            -0.562039        -0.372488          0.065543   \n",
       "184                              0.777535         3.177868          1.018590   \n",
       "\n",
       "           AUM  sales_curr  sales_12M_2018  redemption_curr  redemption_12M  \\\n",
       "4081 -0.088949   -0.083247       -0.154606         0.090417        0.156246   \n",
       "184  -0.124508   -0.082219       -0.139641         0.090417        0.071676   \n",
       "\n",
       "      new_Fund_added_12M_2018  aum_AC_EQUITY  aum_AC_FIXED_INCOME_MUNI  \\\n",
       "4081                 0.436844      -0.026493                 -0.070601   \n",
       "184                  3.848384       0.050153                 -0.166822   \n",
       "\n",
       "      aum_AC_FIXED_INCOME_TAXABLE  aum_AC_MONEY  aum_AC_MULTIPLE  \\\n",
       "4081                    -0.059801     -0.012455        -0.023802   \n",
       "184                     -0.059801     -0.012455        -0.023802   \n",
       "\n",
       "      aum_AC_PHYSICAL_COMMODITY  aum_AC_REAL_ESTATE  aum_AC_TARGET  aum_P_529  \\\n",
       "4081                  -0.041821           -0.037655      -0.040002  -0.070366   \n",
       "184                   -0.041821           -0.037655       0.047651   1.121516   \n",
       "\n",
       "      aum_P_ALT  aum_P_CEF  aum_P_ETF  aum_P_MF  aum_P_SMA  aum_P_UCITS  \\\n",
       "4081  -0.030628  -0.093547  -0.018485 -0.056351  -0.057933    -0.016559   \n",
       "184   -0.030628  -0.093547  -0.018485 -0.160696  -0.158246    -0.016559   \n",
       "\n",
       "      aum_P_UIT  \n",
       "4081  -0.070033  \n",
       "184    3.269629  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_prepared.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORM** the test set (Do NOT fit the pipeline on testing!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prepared = pd.DataFrame(\n",
    "    feat_pipe.transform(X_test),\n",
    "    index=X_test.index,\n",
    "    columns=COLS_TO_KEEP\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_sales_12M_1</th>\n",
       "      <th>no_of_Redemption_12M_1</th>\n",
       "      <th>no_of_sales_12M_10K</th>\n",
       "      <th>no_of_Redemption_12M_10K</th>\n",
       "      <th>no_of_funds_sold_12M_1</th>\n",
       "      <th>no_of_funds_redeemed_12M_1</th>\n",
       "      <th>no_of_fund_sales_12M_10K</th>\n",
       "      <th>no_of_funds_Redemption_12M_10K</th>\n",
       "      <th>no_of_assetclass_sold_12M_1</th>\n",
       "      <th>no_of_assetclass_redeemed_12M_1</th>\n",
       "      <th>no_of_assetclass_sales_12M_10K</th>\n",
       "      <th>no_of_assetclass_Redemption_12M_10K</th>\n",
       "      <th>No_of_fund_curr</th>\n",
       "      <th>No_of_asset_curr</th>\n",
       "      <th>AUM</th>\n",
       "      <th>sales_curr</th>\n",
       "      <th>sales_12M_2018</th>\n",
       "      <th>redemption_curr</th>\n",
       "      <th>redemption_12M</th>\n",
       "      <th>new_Fund_added_12M_2018</th>\n",
       "      <th>aum_AC_EQUITY</th>\n",
       "      <th>aum_AC_FIXED_INCOME_MUNI</th>\n",
       "      <th>aum_AC_FIXED_INCOME_TAXABLE</th>\n",
       "      <th>aum_AC_MONEY</th>\n",
       "      <th>aum_AC_MULTIPLE</th>\n",
       "      <th>aum_AC_PHYSICAL_COMMODITY</th>\n",
       "      <th>aum_AC_REAL_ESTATE</th>\n",
       "      <th>aum_AC_TARGET</th>\n",
       "      <th>aum_P_529</th>\n",
       "      <th>aum_P_ALT</th>\n",
       "      <th>aum_P_CEF</th>\n",
       "      <th>aum_P_ETF</th>\n",
       "      <th>aum_P_MF</th>\n",
       "      <th>aum_P_SMA</th>\n",
       "      <th>aum_P_UCITS</th>\n",
       "      <th>aum_P_UIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>-0.199901</td>\n",
       "      <td>-0.095806</td>\n",
       "      <td>-0.210641</td>\n",
       "      <td>-0.087441</td>\n",
       "      <td>-0.574981</td>\n",
       "      <td>-0.221549</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>0.296800</td>\n",
       "      <td>-0.785202</td>\n",
       "      <td>0.083165</td>\n",
       "      <td>-0.53463</td>\n",
       "      <td>0.777535</td>\n",
       "      <td>-0.372488</td>\n",
       "      <td>0.065543</td>\n",
       "      <td>-0.262627</td>\n",
       "      <td>-0.083366</td>\n",
       "      <td>-0.154761</td>\n",
       "      <td>-0.569226</td>\n",
       "      <td>0.096033</td>\n",
       "      <td>-0.416042</td>\n",
       "      <td>-0.518428</td>\n",
       "      <td>-0.081085</td>\n",
       "      <td>-0.059801</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>-0.023802</td>\n",
       "      <td>6.485925</td>\n",
       "      <td>-0.037655</td>\n",
       "      <td>-0.04036</td>\n",
       "      <td>-0.07523</td>\n",
       "      <td>-0.030628</td>\n",
       "      <td>-0.093547</td>\n",
       "      <td>-0.018485</td>\n",
       "      <td>-0.263819</td>\n",
       "      <td>-0.057933</td>\n",
       "      <td>-0.016559</td>\n",
       "      <td>-0.070033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2758</th>\n",
       "      <td>-0.160716</td>\n",
       "      <td>-0.049687</td>\n",
       "      <td>-0.210641</td>\n",
       "      <td>-0.198657</td>\n",
       "      <td>-0.153437</td>\n",
       "      <td>0.588926</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>-0.441804</td>\n",
       "      <td>0.201462</td>\n",
       "      <td>1.034363</td>\n",
       "      <td>-0.53463</td>\n",
       "      <td>-0.562039</td>\n",
       "      <td>-0.695247</td>\n",
       "      <td>-0.887503</td>\n",
       "      <td>-0.103511</td>\n",
       "      <td>-0.081921</td>\n",
       "      <td>-0.153989</td>\n",
       "      <td>0.090417</td>\n",
       "      <td>0.146670</td>\n",
       "      <td>-0.416042</td>\n",
       "      <td>-0.036794</td>\n",
       "      <td>-0.081085</td>\n",
       "      <td>-0.067561</td>\n",
       "      <td>-0.012455</td>\n",
       "      <td>-0.023802</td>\n",
       "      <td>-0.041821</td>\n",
       "      <td>-0.037655</td>\n",
       "      <td>-0.04036</td>\n",
       "      <td>-0.07523</td>\n",
       "      <td>-0.030628</td>\n",
       "      <td>-0.093547</td>\n",
       "      <td>-0.018485</td>\n",
       "      <td>-0.073685</td>\n",
       "      <td>-0.057933</td>\n",
       "      <td>-0.016559</td>\n",
       "      <td>-0.070033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      no_of_sales_12M_1  no_of_Redemption_12M_1  no_of_sales_12M_10K  \\\n",
       "2052          -0.199901               -0.095806            -0.210641   \n",
       "2758          -0.160716               -0.049687            -0.210641   \n",
       "\n",
       "      no_of_Redemption_12M_10K  no_of_funds_sold_12M_1  \\\n",
       "2052                 -0.087441               -0.574981   \n",
       "2758                 -0.198657               -0.153437   \n",
       "\n",
       "      no_of_funds_redeemed_12M_1  no_of_fund_sales_12M_10K  \\\n",
       "2052                   -0.221549                     -0.43   \n",
       "2758                    0.588926                     -0.43   \n",
       "\n",
       "      no_of_funds_Redemption_12M_10K  no_of_assetclass_sold_12M_1  \\\n",
       "2052                        0.296800                    -0.785202   \n",
       "2758                       -0.441804                     0.201462   \n",
       "\n",
       "      no_of_assetclass_redeemed_12M_1  no_of_assetclass_sales_12M_10K  \\\n",
       "2052                         0.083165                        -0.53463   \n",
       "2758                         1.034363                        -0.53463   \n",
       "\n",
       "      no_of_assetclass_Redemption_12M_10K  No_of_fund_curr  No_of_asset_curr  \\\n",
       "2052                             0.777535        -0.372488          0.065543   \n",
       "2758                            -0.562039        -0.695247         -0.887503   \n",
       "\n",
       "           AUM  sales_curr  sales_12M_2018  redemption_curr  redemption_12M  \\\n",
       "2052 -0.262627   -0.083366       -0.154761        -0.569226        0.096033   \n",
       "2758 -0.103511   -0.081921       -0.153989         0.090417        0.146670   \n",
       "\n",
       "      new_Fund_added_12M_2018  aum_AC_EQUITY  aum_AC_FIXED_INCOME_MUNI  \\\n",
       "2052                -0.416042      -0.518428                 -0.081085   \n",
       "2758                -0.416042      -0.036794                 -0.081085   \n",
       "\n",
       "      aum_AC_FIXED_INCOME_TAXABLE  aum_AC_MONEY  aum_AC_MULTIPLE  \\\n",
       "2052                    -0.059801     -0.012455        -0.023802   \n",
       "2758                    -0.067561     -0.012455        -0.023802   \n",
       "\n",
       "      aum_AC_PHYSICAL_COMMODITY  aum_AC_REAL_ESTATE  aum_AC_TARGET  aum_P_529  \\\n",
       "2052                   6.485925           -0.037655       -0.04036   -0.07523   \n",
       "2758                  -0.041821           -0.037655       -0.04036   -0.07523   \n",
       "\n",
       "      aum_P_ALT  aum_P_CEF  aum_P_ETF  aum_P_MF  aum_P_SMA  aum_P_UCITS  \\\n",
       "2052  -0.030628  -0.093547  -0.018485 -0.263819  -0.057933    -0.016559   \n",
       "2758  -0.030628  -0.093547  -0.018485 -0.073685  -0.057933    -0.016559   \n",
       "\n",
       "      aum_P_UIT  \n",
       "2052  -0.070033  \n",
       "2758  -0.070033  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_prepared.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_pipe = Pipeline([\n",
    "    ('extract_columns_trans', extract_columns_trans),\n",
    "    ('fillna_values_trans', fillna_values_trans),\n",
    "    ('StandardScaler', StandardScaler()),\n",
    "    ('SVD', TruncatedSVD(n_components=3)),\n",
    "#     ('select', SelectFromModel(DecisionTreeRegressor())),\n",
    "    ('xgbr', xgb.XGBRegressor()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[col for col in X_train.columns if '10K' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = X_train[[col for col in X_train.columns if '10K' in col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_pipe.fit(new_X_train, y_train_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = feat_pipe.predict(X_test_prepared[[col for col in X_train.columns if '10K' in col]])\n",
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-cross_validate(feat_pipe, X_train_prepared, y_train_reg, scoring='neg_root_mean_squared_error')['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    print(\"Cross Validation Scores:\")\n",
    "    print(cross_validate(model, X, y, scoring='neg_root_mean_squared_error')['test_score'])\n",
    "    print('-'*55)\n",
    "    preds = np.exp(model.predict(X))\n",
    "    lim = max(preds.max(), y.max())\n",
    "    fig, ax = plt.subplots(1,1,figsize=(7,5))\n",
    "    ax.scatter(x=y, y=preds, alpha=0.4)\n",
    "    ax.plot([0, 10000], [0, 10000])\n",
    "    ax.set_xlim([0, 10000])\n",
    "    ax.set_ylim([0, 10000])\n",
    "    ax.set_title(\"Actual vs Predicted - Regression\")\n",
    "    ax.set_xlabel(\"Actual\")\n",
    "    ax.set_ylabel(\"Predicted\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(feat_pipe, X_train_prepared, y_train_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reg_log = np.log(y_train_reg+1)\n",
    "y_test_reg_log = np.log(y_test_reg+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_pipe.fit(X_train_prepared, y_train_reg_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_pipe.predict(X_test_prepared)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(1.5966611)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(feat_pipe, X_train, y_train_reg_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(feat_pipe, X_test, y_test_reg_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is feature engineering**?\n",
    "\n",
    "\"Coming up with features is difficult, time-consuming, requires expert knowledge. 'Applied machine learning' is basically feature engineering.\" - Andrew Ng\n",
    "\n",
    "Feature engineering is the term broadly applied to the creation and manipulation of features (variables) used in machine learning algorithms. Unless we're working with the same data over and over again, this isn't something we can automate. It will require creativity and a good, thorough understanding of our data.\n",
    "\n",
    "Regression results can change significantly depending on feature selection. Let's take a closer look at our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared.corr().style.background_gradient().set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_prepared.hist(bins=40, figsize=(16,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Variable Inflation Factor (VIF)\n",
    "\n",
    "VIF measures the amount of multicollinearity in a set of multiple regressors, by evaluating how much the variance of the independent variable is inflated by it's interaction with other independent variables. VIF threshold of 5 to 10 are acceptable, but values above 10 are too high.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "class ReduceVIF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, thresh=10.0, impute=True, impute_strategy='median'):\n",
    "        # From looking at documentation, values between 5 and 10 are \"okay\".\n",
    "        # Above 10 is too high and so should be removed.\n",
    "        self.thresh = thresh\n",
    "        \n",
    "        # The statsmodel function will fail with NaN values, as such we have to impute them.\n",
    "        # By default we impute using the median value.\n",
    "        # This imputation could be taken out and added as part of an sklearn Pipeline.\n",
    "        if impute:\n",
    "            self.imputer = SimpleImputer(strategy=impute_strategy)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        print('ReduceVIF fit')\n",
    "        if hasattr(self, 'imputer'):\n",
    "            self.imputer.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        print('ReduceVIF transform')\n",
    "        columns = X.columns.tolist()\n",
    "        if hasattr(self, 'imputer'):\n",
    "            X = pd.DataFrame(self.imputer.transform(X), columns=columns)\n",
    "        return ReduceVIF.calculate_vif(X, self.thresh)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_vif(X, thresh=5.0):\n",
    "        # Taken from https://stats.stackexchange.com/a/253620/53565 and modified\n",
    "        dropped=True\n",
    "        while dropped:\n",
    "            variables = X.columns\n",
    "            dropped = False\n",
    "            vif = [variance_inflation_factor(X[variables].values, X.columns.get_loc(var)) for var in X.columns]\n",
    "            \n",
    "            max_vif = max(vif)\n",
    "            if max_vif > thresh:\n",
    "                maxloc = vif.index(max_vif)\n",
    "                print(f'Dropping {X.columns[maxloc]} with vif={max_vif}')\n",
    "                X = X.drop([X.columns.tolist()[maxloc]], axis=1)\n",
    "                dropped=True\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funds = pd.concat([X_train_prepared, y_train_reg.to_frame()], axis=1)\n",
    "features = funds.columns.tolist()\n",
    "target = 'sales_12M_2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ReduceVIF()\n",
    "\n",
    "X_tr_vif = transformer.fit_transform(X_train_prepared, y_train_reg)\n",
    "X_tr_vif.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = feat_pipe.predict(X_test_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get residuals\n",
    "residuals = y_test_preds - y_test_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions vs residuals\n",
    "fig, axes = plt.subplots(2,2,figsize=(14,10))\n",
    "\n",
    "# plot scatter on upper right plot\n",
    "axes[0,0].scatter(x=y_test_preds, y=residuals, alpha=0.5)\n",
    "axes[0,0].set(xlabel=\"Residuals\",ylabel=\"Predictions\");\n",
    "\n",
    "# plot hist on upper left plot\n",
    "axes[0,1].hist(residuals, bins=50)\n",
    "axes[0,1].set(xlabel='Residuals', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.api import qqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes[1,0].set_ylim([-3.5, 3.5])\n",
    "axes[1,0].set_xlim([-3.5, 3.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqplot(residuals, fit=True, line='r', ax=axes[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "# Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Index)\n",
    "## Condition number\n",
    "\n",
    "Numerical analysis has a notion of condition number, which measures how sensitive a function is to changes in the input, and how much error in the output results from an error in the input. In linear regression this number can be used to diagnose multicollinearity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# Find all possible combinations of any length more than 2\n",
    "def all_subsets(set_arg):\n",
    "    return chain(*map(lambda x: combinations(set_arg, x), range(2, len(set_arg)+1)))\n",
    "\n",
    "funds = pd.concat([X_train_prepared, y_train_reg.to_frame()], axis=1)\n",
    "features = funds.columns.tolist() \n",
    "target = 'sales_12M_2019'\n",
    "\n",
    "cond_nums = {}\n",
    "for subset in all_subsets(features):\n",
    "    # checking that target varaible is included in the matrix\n",
    "    if target not in list(subset):\n",
    "        continue\n",
    "    cond_nums[', '.join(list(subset))] = LA.cond(funds[list(subset)])\n",
    "    \n",
    "sorted(cond_nums.items(), key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
